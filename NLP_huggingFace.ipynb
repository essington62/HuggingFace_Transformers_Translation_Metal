{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ipywidgets\n",
    "# ! jupyter nbextension enable --py widgetsnbextension\n",
    "# ! pip install jupyter_contrib_nbextensions\n",
    "# ! jupyter contrib nbextension install --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carregar um pipeline de NER pré-treinado\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "# Texto de exemplo\n",
    "text = \"\"\"\n",
    "Kundalini Yoga offers multiple benefits for cognition and memory in older women at risk of Alzheimer's Disease.\n",
    "\"\"\"\n",
    "\n",
    "# Extração de entidades\n",
    "entities = ner_pipeline(text)\n",
    "\n",
    "# Mostrar os resultados\n",
    "for entity in entities:\n",
    "    print(f\"Texto: {entity['word']}, Entidade: {entity['entity']}, Score: {entity['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_entities(entities):\n",
    "    result = []\n",
    "    current_entity = {\"word\": \"\", \"entity\": None, \"score\": 0.0}\n",
    "    \n",
    "    for entity in entities:\n",
    "        if entity[\"entity\"].startswith(\"B-\"):\n",
    "            # Adiciona a entidade atual ao resultado antes de começar uma nova\n",
    "            if current_entity[\"word\"]:\n",
    "                result.append(current_entity)\n",
    "            # Inicia uma nova entidade\n",
    "            current_entity = {\"word\": entity[\"word\"], \"entity\": entity[\"entity\"], \"score\": entity[\"score\"]}\n",
    "        elif entity[\"entity\"].startswith(\"I-\") and current_entity[\"entity\"]:\n",
    "            # Continua a entidade atual\n",
    "            current_entity[\"word\"] += entity[\"word\"].replace(\"##\", \"\")\n",
    "            current_entity[\"score\"] = max(current_entity[\"score\"], entity[\"score\"])\n",
    "        else:\n",
    "            # Caso não seja uma entidade válida, pula\n",
    "            if current_entity[\"word\"]:\n",
    "                result.append(current_entity)\n",
    "            current_entity = {\"word\": \"\", \"entity\": None, \"score\": 0.0}\n",
    "    \n",
    "    # Adiciona a última entidade ao resultado\n",
    "    if current_entity[\"word\"]:\n",
    "        result.append(current_entity)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Usando a função após a extração\n",
    "entities = ner_pipeline(text)\n",
    "cleaned_entities = reconstruct_entities(entities)\n",
    "\n",
    "# Mostrar os resultados\n",
    "for entity in cleaned_entities:\n",
    "    print(f\"Texto: {entity['word']}, Entidade: {entity['entity']}, Score: {entity['score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Função para reconstruir entidades fragmentadas\n",
    "def reconstruct_entities(entities):\n",
    "    result = []\n",
    "    current_entity = {\"word\": \"\", \"entity\": None, \"score\": 0.0}\n",
    "    \n",
    "    for entity in entities:\n",
    "        if entity[\"entity\"].startswith(\"B-\"):\n",
    "            # Adiciona a entidade atual ao resultado antes de começar uma nova\n",
    "            if current_entity[\"word\"]:\n",
    "                result.append(current_entity)\n",
    "            # Inicia uma nova entidade\n",
    "            current_entity = {\"word\": entity[\"word\"], \"entity\": entity[\"entity\"], \"score\": entity[\"score\"]}\n",
    "        elif entity[\"entity\"].startswith(\"I-\") and current_entity[\"entity\"]:\n",
    "            # Continua a entidade atual\n",
    "            current_entity[\"word\"] += entity[\"word\"].replace(\"##\", \"\")\n",
    "            current_entity[\"score\"] = max(current_entity[\"score\"], entity[\"score\"])\n",
    "        else:\n",
    "            # Caso não seja uma entidade válida, pula\n",
    "            if current_entity[\"word\"]:\n",
    "                result.append(current_entity)\n",
    "            current_entity = {\"word\": \"\", \"entity\": None, \"score\": 0.0}\n",
    "    \n",
    "    # Adiciona a última entidade ao resultado\n",
    "    if current_entity[\"word\"]:\n",
    "        result.append(current_entity)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Carregar o pipeline de NER\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", device=0)\n",
    "\n",
    "# Função para processar um arquivo de texto\n",
    "def process_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Executar NER no texto\n",
    "    entities = ner_pipeline(text)\n",
    "    \n",
    "    # Reconstruir entidades\n",
    "    reconstructed_entities = reconstruct_entities(entities)\n",
    "    \n",
    "    # Mostrar os resultados\n",
    "    print(\"Entidades Encontradas:\")\n",
    "    for entity in reconstructed_entities:\n",
    "        print(f\"Texto: {entity['word']}, Entidade: {entity['entity']}, Score: {entity['score']:.2f}\")\n",
    "\n",
    "# Caminho do arquivo de texto\n",
    "file_path = \"/Users/edmundobrown/Documents/PosYoga/dados/Ingles/docsCientificos(text)/11387275.txt\"  # Substituir pelo caminho do seu arquivo de texto\n",
    "\n",
    "# Processar o arquivo de texto\n",
    "process_text_file(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando se a sentença esta relacionada a Yoga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carregar um pipeline de classificação\n",
    "classifier = pipeline(\"text-classification\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Texto de exemplo\n",
    "text = \"Kundalini Yoga offers multiple benefits for cognition and memory.\"\n",
    "\n",
    "# Classificar o texto\n",
    "result = classifier(text)\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Carregar o pipeline de classificação com um modelo adequado\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Texto de exemplo\n",
    "text = \"Kundalini Yoga offers multiple benefits for cognition and memory.\"\n",
    "\n",
    "# Classificar o texto\n",
    "result = classifier(text)\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o modelo de linguagem do spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Frases de interesse\n",
    "conditions = [\"Alzheimer\", \"menopause\", \"cognitive decline\"]\n",
    "yoga_practices = [\"Kundalini Yoga\", \"Yoga\", \"Pilates\", \"meditation\"]\n",
    "\n",
    "# Configurar o PhraseMatcher\n",
    "matcher_conditions = PhraseMatcher(nlp.vocab)\n",
    "matcher_yoga = PhraseMatcher(nlp.vocab)\n",
    "matcher_conditions.add(\"CONDITIONS\", [nlp.make_doc(text) for text in conditions])\n",
    "matcher_yoga.add(\"YOGA\", [nlp.make_doc(text) for text in yoga_practices])\n",
    "\n",
    "def extract_key_information(text):\n",
    "    \"\"\"\n",
    "    Extrai informações-chave do texto usando spaCy.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    matches_conditions = matcher_conditions(doc)\n",
    "    matches_yoga = matcher_yoga(doc)\n",
    "\n",
    "    # Condições encontradas\n",
    "    found_conditions = [doc[start:end].text for match_id, start, end in matches_conditions]\n",
    "    # Práticas de Yoga encontradas\n",
    "    found_yoga = [doc[start:end].text for match_id, start, end in matches_yoga]\n",
    "\n",
    "    return {\n",
    "        \"conditions\": list(set(found_conditions)),\n",
    "        \"yoga_practices\": list(set(found_yoga)),\n",
    "    }\n",
    "\n",
    "# Diretório de arquivos texto\n",
    "input_folder = \"/Users/edmundobrown/Documents/PosYoga/dados/Ingles/docsCientificos(text)\"\n",
    "results = []\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            data = extract_key_information(text)\n",
    "            results.append({\n",
    "                \"file\": filename,\n",
    "                \"conditions\": \", \".join(data[\"conditions\"]),\n",
    "                \"yoga_practices\": \", \".join(data[\"yoga_practices\"]),\n",
    "            })\n",
    "\n",
    "# Salvar os resultados em CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "output_file = \"extracted_yoga_conditions.csv\"\n",
    "df_results.to_csv(output_file, index=False)\n",
    "print(f\"Resultados salvos em: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
